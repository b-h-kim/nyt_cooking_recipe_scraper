{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264c0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import timeit\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import yaml\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b273cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_lst = []\n",
    "\n",
    "recipe_lst.append(list(range(1000,12849)))\n",
    "\n",
    "for y in [str(year) for year in list(range(1013,1023+1))]:\n",
    "    for n in [str(recipe_no).zfill(3) for recipe_no in list(range(1, 999))]:\n",
    "        recipe_lst.append(y + n)\n",
    "\n",
    "# newest recipe first\n",
    "recipe_lst = list(reversed(recipe_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29264805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc144897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in list(chunker(recipe_no, 250)):\n",
    "    recipes = []\n",
    "    \n",
    "    for r in chunk:\n",
    "        # soup\n",
    "        link = f'https://cooking.nytimes.com/recipes/{r}'\n",
    "        reqs = requests.get(link)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "        values = {}\n",
    "        description = []\n",
    "        ingredients = []\n",
    "        directions = []\n",
    "        note = []\n",
    "\n",
    "        try:\n",
    "            # description\n",
    "            description.append(soup.find('div', attrs = {'class': 'recipeintro_topnote-block__hFFPr'}).find('p').text.strip())\n",
    "            description.append('Rating: ' + soup.find('dd', attrs = {'class' : 'pantry--ui stats_ratingInfo__PUgd2'}).text.strip())\n",
    "\n",
    "            # ingredients\n",
    "            i_lst = soup.findAll('li', attrs = {'class' : 'pantry--ui ingredient_ingredient__lq70t'})\n",
    "            for i in i_lst:\n",
    "                if len(i.findAll('span')) > 1:\n",
    "                    ingredients.append(i.findAll('span')[0].text.strip() + ' ' + i.findAll('span')[1].text.strip())\n",
    "                elif len(i.findAll('span')) == 1:\n",
    "                    ingredients.append(i.findAll('span')[0].text.strip())\n",
    "\n",
    "            # preparation        \n",
    "            p_lst = soup.find('div', attrs = {'class' : 'recipebody_prep-block__cpC8w'}).findAll('p')\n",
    "            for i in p_lst:\n",
    "                directions.append(i.text.strip())\n",
    "\n",
    "            # note\n",
    "            try:\n",
    "                t_lst = soup.find('div', attrs = {'class' : 'tips_tips__iZQZC'}).findAll('li')\n",
    "                for i in t_lst:\n",
    "                    if len(t_lst) == 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        note.append(i.text.strip())\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "            # update values\n",
    "            values.update(\n",
    "                {'name' : soup.find('h1').text.strip(),\n",
    "                 'servings' : soup.find('span', attrs = {'class' : 'pantry--ui ingredients_fontOverride__WoKY5'}).text.strip(),\n",
    "                 'source':soup.findAll('h2')[0].find('a').text.strip(),\n",
    "                 'source_url' : link,\n",
    "                 'cook_time': soup.find('div', attrs = {'class' : 'recipeintro_stats-block__YgbqJ'}).findAll('dd')[0].text.strip(),\n",
    "                 'nutritional_info' : soup.find('h5').next_sibling.text.strip(),\n",
    "                 'description' : '\\n\\n'.join(description),\n",
    "                 'ingredients' : '\\n'.join(ingredients),\n",
    "                 'directions' : '\\n\\n'.join(directions),\n",
    "                 'notes' : '\\n\\n'.join(note)\n",
    "                })\n",
    "\n",
    "            # update image if available\n",
    "            if soup.find('div', attrs = {'class' : 'recipeheaderimage_image___CZR1'}):\n",
    "                values.update(\n",
    "                    {'photo' : base64.b64encode(requests.get(soup.find('div', attrs = {'class' : 'recipeheaderimage_image___CZR1'}).find('img')['src'].split('?')[0]).content).decode('ascii')\n",
    "                    })\n",
    "\n",
    "            recipes.append(values)\n",
    "\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    recipe_no_range = str(chunk[0]) + '-' + str(chunk[-1])\n",
    "\n",
    "    # export it to YAML file\n",
    "    with open(f\"../data/recipes_{recipe_no_range}.yml\", \"w\", encoding = 'utf-8') as file:\n",
    "        yaml.dump(recipes, file, width=10000)\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print(recipe_range + '_Finished ' + timeit.default_timer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
